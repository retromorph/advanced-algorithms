{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Теория вероятностей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Базовые понятия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Определение:** Конечное вероятностное пространство (finite probability space) - это пара $\\langle\\Omega, P\\rangle$, где\n",
    "1. $\\Omega$ - конечное множество элементарных исходов (sample space)\n",
    "2. $P: 2^\\Omega \\longrightarrow [0, 1]$ - вероятностная мера (probability measure)\n",
    "3. $P(\\Omega) = 1$\n",
    "4. $\\forall A, B \\subset \\Omega$ - непересекающиеся подмножества, $P(A \\cup B) = P(A) + P(B)$ - аддитивность\n",
    "\n",
    "_Замечание:_ В общем случае $\\Omega$ может быть бесконечным множеством. В таком случае $P$ будет являться произвольной мерой на этом множестве. Например $\\Omega = \\mathbb{R}^2$ с площадью. Строго мы это не вводим, но пользоваться можно. Это еще называют геометрической вероятностью (geometric probability)\n",
    "\n",
    "**Определение:** Подмножество $A$ множества элементарных исходов $\\Omega$ называется событием (event)\n",
    "\n",
    "**Определение:** Событие называется невозможным (impossible event), если $P(A) = 0$\n",
    "\n",
    "**Определение:** Событие называется достоверным (sure event), если $P(A) = 1$\n",
    "\n",
    "**Определение:** События $A$ и $B$ называются несовместными (disjoint events), если $P(A \\cap B) = 0$\n",
    "\n",
    "**Лемма:**\n",
    "\n",
    "(1) $P(\\neg A) = 1 - P(A)$\n",
    "\n",
    "(2) $P(A \\cup B) = P(A) + P(B) - P(A \\cap B)$\n",
    "\n",
    "(3) $P(A_1 \\cup ... \\cup A_n) = P(A_1) + ... + P(A_n) - P(A_1 \\cap A_2) - ... - P(A_{n - 1} \\cap A_n) + P(A_1 \\cap A_2 \\cap A_3) + ...$ формула включений-исключений (inclusion–exclusion principle)\n",
    "\n",
    "(4) $P(A_1 \\cup ... \\cup A_n) \\le \\sum_{i = 1}^{n} A_i$\n",
    "\n",
    "$\\square$\n",
    "Все факты очевидны из теоретико-множественных соображений, оставлю без доказательства\n",
    "$\\blacksquare$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры\n",
    "\n",
    "**Игральный кубик:**\n",
    "\n",
    "$\\Omega = \\{\\omega_1, \\omega_2, \\omega_3, \\omega_4, \\omega_5, \\omega_6\\}$ - пространство бросаний шестигранного кубика, $\\forall i$ $P(\\omega_i) = \\frac{1}{6}$\n",
    "\n",
    "**Задача о беспорядках**\n",
    "\n",
    "70 студентов сидели на своих местах в 70-местной аудитории. Их попросили пересесть случайным образом. Требуется найти вероятность того, что все студенты сели не на свои изначальные места.\n",
    "\n",
    "$A$ - событие \"все ученики сидят не на своем месте\"\n",
    "\n",
    "$B_i$ - событие \"ученик $i$ сидит на своем месте\"\n",
    "\n",
    "$P(A) = 1 - P(\\neg A) = 1 - \\frac{\\#(A_1 \\cup ... \\cup A_{70})}{70!} = $ \n",
    "\n",
    "По формуле включений-исключений:\n",
    "\n",
    "$ = 1 - \\frac{\\binom{70}{1}69! - \\binom{70}{2}68! + ... - \\binom{70}{70}1!}{70!} = 1 - \\frac{1}{1!} + \\frac{1}{2!} - \\frac{1}{3!} + ... - \\frac{1}{70!} \\simeq e^{-1}$\n",
    "\n",
    "**Геометрическая вероятность:**\n",
    "\n",
    "Коля и Вася договорились о встрече в промежуток с 9:00 до 10:00. Оба приходят в случайный момент времени из этого промежутка и ждут в течение 15 минут. Т.н. вероятность встречи.\n",
    "\n",
    "<img src=\"../../static/IMG_C984BA21888F-1.jpeg\" width=\"600\">\n",
    "<br />\n",
    "\n",
    "$A$ - событие встречи (закрашено красным)\n",
    "\n",
    "$P(A) = 1 - \\frac{3}{4}^2 = \\frac{7}{16}$ - площадь красной области"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Определение:** Условная вероятность (conditional probability) - вероятность наступления события $A$ при наступившем событии $B$. Вычисляется по формуле $P(A | B) = \\frac{P(A \\cap B)}{P(B)}$\n",
    "\n",
    "**Определение:** События $A$ и $B$ называются независимыми (independent), если $P(A \\cap B) = P(A) \\cdot P(B)$ или, что эквивалентно $P(A | B) = P(A)$\n",
    "\n",
    "\n",
    "Пусть $\\alpha = \\left\\{ A_1, A_2, ..., A_n \\right\\}$ - множество событий, тогда\n",
    "\n",
    "**Определение:** Оно называется попарно независимым (pairwise independent), если $\\forall i, j < n$ $A_i$ и $A_j$ - независимы\n",
    "\n",
    "**Определение:** Оно называется независимым в совокупности (mutually independent), если $\\forall I \\subset \\{1, ..., n\\}$ $P\\bigg(\\bigcap_{i \\in I} A_i\\bigg) = \\prod_{i \\in I} P(A_i)$\n",
    "\n",
    "### Примеры\n",
    "\n",
    "**Игральный кубик**\n",
    "\n",
    "Продемонстрируем разницу между попарной независимостью и независимостью в совокупности.\n",
    "Рассмотрим вероятностное пространство бросания двух кубиков.\n",
    "Выберем такие события:\n",
    "1. На первом кубике выпало четное число\n",
    "2. На втором кубике выпало четное число\n",
    "3. Сумма чисел на двух кубиках четна\n",
    "\n",
    "Эти события являются попарно независимыми, но не в совокупности. Действительно, (1) и (2) независимы по определению, (1) и (3) независимы, так как четность суммы зависит и от события (2), то же самое можно сказать и про пару (2) и (3), т.о. они и правда попарно независимы. Однако же очевидно, что они не могут быть независимыми в совокупности, ведь четность суммы однозначно определяется через четность слагаемых.\n",
    "\n",
    "**Разноцветный тетраэдр**\n",
    "Другой пример - Тетраэдр, с одной красной, одной зеленой, одной синей и одной красно-зелено-синей полосатой гранью.\n",
    "$R$ - событие «на стороне есть красный цвет»\n",
    "$G$ - событие «на стороне есть зеленый цвет»\n",
    "$B$ - событие «на стороне есть синий цвет»\n",
    "\n",
    "Очевидно, что:\n",
    "$P(R) = P(G) = P(B) = \\frac{1}{2}$\n",
    "\n",
    "Попарная независимость наблюдается:\n",
    "$P(R \\cap G) = P(R \\cap B) = P(G \\cap B) = \\frac{1}{4} = \\frac{1}{2} \\cdot \\frac{1}{2}$\n",
    "\n",
    "Однако независимости в совокупности нет:\n",
    "$P(R \\cap G \\cap B) = \\frac{1}{4} \\neq \\frac{1}{8}$\n",
    "\n",
    "**Раскраски**\n",
    "Пусть есть множество $A = \\{1, 2, 3, 4, 5, 6\\}$ и два цвета. Очевидно, всего есть $2^6 раскрасок$.\n",
    "\n",
    "$A_{ij}$ - $i$ и $j$ раскрашены в один цвет\n",
    "\n",
    "$P(A_{ij}) = \\frac{1}{2}$\n",
    "$P(A_{ij} \\cap A_{kl}) = $\n",
    "\n",
    "$P(A_{ijk}) = $\n",
    "\n",
    "Случайная раскраска в два цвета (интересный случай)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Теорема Байеса (Bayes):**\n",
    "\n",
    "$P(A | B) = \\frac{P(B | A) \\cdot P(A)}{P(B)}$\n",
    "\n",
    "$\\square$\n",
    "\n",
    "По определению условной вероятности:\n",
    "$P(A | B) = \\frac{P(A \\cap B)}{P(B)}$, т.о.\n",
    "(1) $P(A \\cap B) = \\frac{P(A | B)}{P(B)}$\n",
    "\n",
    "По определению условной вероятности:\n",
    "$P(B | A) = \\frac{P(A \\cap B)}{P(A)}$, т.о.\n",
    "(2) $P(A \\cap B) = \\frac{P(B | A)}{P(A)}$\n",
    "\n",
    "Приравняв получим (1) и (2):\n",
    "$P(A | B) = \\frac{P(B | A) \\cdot P(A)}{P(B)}$\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "### Примеры\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Определение:** Множество событий $\\left\\{ A_1, A_2, ..., A_n \\right\\}$ образует полную группу (collectively exhaustive events) в вероятностном пространстве $\\Omega$, если:\n",
    " 1. $\\forall A_i, A_j$ $P(A_i \\cap A_j) = 0$, т.е. все события несовместимы\n",
    " 2.  $\\sum_{i}{P(A_i)} = 1$, при этом они покрывают все вероятностное пространство $\\Omega$\n",
    "\n",
    "### Примеры:\n",
    "<br/>\n",
    "<img src=\"../../static/IMG_09F686348EDB-1.jpeg\" width=\"400\"/>\n",
    "<br/>\n",
    "\n",
    "Таким образом вероятность события $B$ в этом пространстве $\\Omega$ можно выразить через элементы полной группы как:\n",
    "$P(B) = \\sum_{i}{P(B | A_i) \\cdot P(A_i)}$\n",
    "\n",
    "<br/>\n",
    "<img src=\"../../static/IMG_252744EDB449-1.jpeg\" width=\"400\"/>\n",
    "<br/>\n",
    "\n",
    "_Замечание:_ Это чем-то напоминает факторизацию в алгебре\n",
    "\n",
    "+ С теоремой байеса\n",
    "**Пример:** Урновая схема"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Схема испытаний Бернулли (Биномиальная схема)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Определение:** Испытание Бернулли - случайный опыт, который может закончиться одним из двух элементарных событий - успех ($1$) либо неудача ($0$). Вероятность успеха обозначается $p \\in [0, 1]$, соответственно вероятность неудачи $q = 1 - p$.\n",
    "\n",
    "**Определение** Схема испытаний Бернулли - это последовательность из $n$ испытаний бернулли\n",
    "\n",
    "Свойства схемы испытаний Бернулли:\n",
    "1. Вероятностное пространство $\\Omega = \\{0, 1\\}^n$\n",
    "2. $\\#\\Omega = 2^n$\n",
    "3. $P(\\omega) = p^k \\cdot q^{n - k}$, где $k$ - кол-во успехов\n",
    "4. Если событие A - произошло k успехов, то $P(A) = \\binom{n}{k} \\cdot p^k \\cdot q^{n - k}$\n",
    "\n",
    "## Примеры:\n",
    "Случайное блуждание на прямой\n",
    "\n",
    "Случайный граф\n",
    "\n",
    "Теорема Эрдёша\n",
    "\n",
    "**Определение:** Мультиномиальная схема -\n",
    "\n",
    "## Примеры:\n",
    "Теорема эрдеша-радо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Полиномиальная схема"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Определение:** Полиномиальное испытание - случайный опыт, который может закончиться одним из $m$ элементарных исходов - $\\omega_1, ..., \\omega_m$.\n",
    "\n",
    "**Определение** Полиномиальная схема - это последовательность из $n$ полиномиальных испытаний\n",
    "\n",
    "Свойства схемы Полиномиальной схемы:\n",
    "1. Вероятностное пространство - $\\Omega = \\{\\omega_1, ..., \\omega_m\\}^n$\n",
    "2. $\\#\\Omega = m^n$\n",
    "3. $P(\\omega) = \\rho(\\omega_1)^{\\alpha_1} \\cdot ...$\n",
    "4. $P(A) = \\binom{n}{k_1, ..., k_m} \\cdot P(\\omega)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Теорема Ван-дер-ваардена"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Случайные величины"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Определение:** Случайная величина (random variable) - это произвольное отображение $\\xi: \\Omega \\longrightarrow \\mathbb{R}$\n",
    "\n",
    "**Определение:** Распределение случайной величины $\\xi$ - это функция $F: \\mathbb{R} \\longrightarrow [0, 1]$, т.ч.\n",
    "$F(x) = P(\\xi = x)$\n",
    "\n",
    "**Определение:** (!!!!!!) Случайные величины $\\xi$ и $\\psi$ называются независимыми, если $\\forall x, y \\in \\mathbb{R} \\mbox{ } (x \\neq y)$ $A = P(\\xi = x)$ и $B = P(\\psi = y)$ - $A$ и $B$ независимы\n",
    "\n",
    "_Замечание:_ По аналогии, можно ввести понятие попарных независимых и независимых в совокупности случайных величин\n",
    "\n",
    "**Пример:**\n",
    "Предположим мы играем в игру с монеткой с такими правилами:\n",
    "1. Если выпал орел, мы теряем 100 рублей\n",
    "2. Если выпала решка, мы получаем 100 рублей\n",
    "\n",
    "Тогда интуитивно можно ввести случайную величину $\\xi$ таким образом:\n",
    "\\begin{align}\n",
    "$\\xi =$\n",
    "\\begin{cases}\n",
    "-100, & \\mbox{ } \\omega \\mbox{ - орел} \\\\\n",
    "100, & \\mbox{ } \\omega \\mbox{ - решка}\n",
    "\\end{cases}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры\n",
    "\n",
    "**Распределение Бернулли**\n",
    "\n",
    "$\\xi \\sim \\text{U}(n)$, $n \\in \\mathbb{N}$ т. и т.т.\n",
    "\n",
    "$\\text{val}(\\xi) = \\{x_1, x_2, ..., x_n\\}$ и $\\forall i$ $P(\\xi = x_i) = \\frac{1}{n}$\n",
    "\n",
    "\n",
    "\n",
    "**Распределение Бернулли**\n",
    "\n",
    "$\\xi \\sim \\text{Bern}(p)$, $p \\in [0, 1]$ т. и т.т.\n",
    "\n",
    "$\\text{val}(\\xi) = \\{x_1, x_2\\}$ и $P(\\xi = x_1) = p$, $P(\\xi = x_2) = 1 - p$\n",
    "\n",
    "\n",
    "**Биномиальное распределение**\n",
    "\n",
    "$\\xi \\sim \\text{Bin}(n, p)$, $n \\in \\mathbb{N}$, $p \\in [0, 1]$ т. и т.т.\n",
    "\n",
    "$\\text{val}(\\xi) = \\{x_1, x_2, ..., x_n\\}$ и $\\forall i$ $P(\\xi = x_i) = \\binom{n}{i} \\cdot p^k \\cdot (1 - p)^{n - k}$\n",
    "\n",
    "\n",
    "**Пуассоновское распределение**\n",
    "\n",
    "\n",
    "**Геометрическое распределение**\n",
    "\n",
    "**Гипергеометрическое распределение**\n",
    "\n",
    "**Распределение Паскаля**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Определение:** Математическое ожидание (expected value) случайной величины - взвешенное среднее ее значений, т.е. $E\\xi = \\sum_{\\omega \\in \\Omega}{\\xi(\\omega) \\cdot P(\\omega)}$\n",
    "\n",
    "**Замечание:** То же самое можно записать грубо говоря «по Лебегу» $E\\xi = \\sum_{y \\in cod(\\xi)}{y \\cdot P(\\omega : \\xi(\\omega) = y)}$\n",
    "\n",
    "**Пример:**\n",
    "Посчитаем матожидание случайной величины из предыдущего примера с игрой с монеткой:\n",
    "$E\\xi = -100 \\cdot \\frac{1}{2} + 100 \\cdot \\frac{1}{2} = 0$\n",
    "\n",
    "+ простейшие св-ва\n",
    "\n",
    "**Теорема о линейности математического ожидания**\n",
    "$E(\\alpha\\xi + \\beta\\psi) = \\alpha \\cdot E\\xi + \\beta \\cdot E\\psi$\n",
    "\n",
    "$\\square$\n",
    "\n",
    "$E(\\alpha\\xi + \\beta\\psi) = \\sum_{\\omega \\in \\Omega}{\\bigg(\\alpha\\xi(\\omega) + \\beta\\psi(\\omega)\\bigg)} = E(\\alpha\\xi) + E(\\beta\\psi) = \\alpha \\cdot E\\xi + \\beta \\cdot E\\psi$\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "+ перенести сюда теорему о незав матожидании\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Определение:** Индикаторная случайная величина (indicator random value) - это функция вида\n",
    "\\begin{align}\n",
    "I_A(\\omega) =\n",
    "\\begin{cases}\n",
    "1, & \\mbox{ } \\omega \\in A \\\\\n",
    "0, & \\mbox{ } \\omega \\notin A\n",
    "\\end{cases}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Задача о назначениях:**\n",
    "\n",
    "Пусть есть множество $A$ работников, множество $T$ работ и функция стоимости $C : A \\times T \\longrightarrow  \\mathbb{R}$. Обычно функция стоимости задается в виде матрицы $C$\n",
    "Необходимо найти биекцию $f : A \\longrightarrow T$, такую что сумма $\\sum_{a \\in A} C(a, f(a))$ минимальна.\n",
    "\n",
    "В общем случае эта задача решается венгерским алгоритмом, но в обучающих целях рассмотрим, что будет, если мы попытаемся в качестве ответа брать случайную функцию $f$. Посчитаем математическое ожидание:\n",
    "\n",
    "$E\\xi = E\\bigg(\\sum_{i = 1}^{n}\\sum_{j = 1}^{n} I_{c_{ij}} \\cdot c_{ij}\\bigg) = \\sum_{i = 1}^{n}\\sum_{j = 1}^{n} c_{ij} \\cdot E(I_{c_{ij}}) = \\frac{\\sum_{i = 1}^{n}\\sum_{j = 1}^{n} c_{ij}}{n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Задача максимального разреза:**\n",
    "\n",
    "Пусть у нас есть граф $G$.\n",
    "Необходимо найти максимальный разрез этого графа, т.е. такое подмножество вершин, что у максимального количества ребер одна вершина лежит в этом подмножестве, а вторая нет. Например:\n",
    "\n",
    "<img src=\"../../static/IMG_F4D34D90BF7D-1.jpeg\" width=\"1000\">\n",
    "\n",
    "Для этой задачи неизвестен полиномиальный алгоритм решения, поэтому давайте попробуем посчитать матожидание случайного равновероятного выбора вершин в подмножество. Т. е. мы будем проходиться по всем вершинам графа и с вероятностью $\\frac{1}{2}$ брать их в разрез.\n",
    "\n",
    "Введем индикаторную случайную величину:\n",
    "\\begin{align}\n",
    "I_c = I_{uv} =\n",
    "\\begin{cases}\n",
    "1, & \\mbox{ } u \\in A, v \\in \\overline{A} \\\\\n",
    "1, & \\mbox{ } u \\in \\overline{A}, v \\in A \\\\\n",
    "0, & \\mbox{ } u \\in A, v \\in A \\\\\n",
    "0, & \\mbox{ } u \\in \\overline{A}, v \\in \\overline{A} \\\\\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "Тогда:\n",
    "$E\\bigg(\\sum I_c\\bigg) = \\sum E(I_c) = \\sum P(A_{uv}) = \\frac{\\epsilon(G)}{2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Наибольшая возрастающая подпоследовательность:**\n",
    "\n",
    "Пусть у нас есть массив $A$.\n",
    "Необходимо найти наибольший возрастающий подмассив в $A$.\n",
    "\n",
    "Эта задача решается методом динамического программирования, однако в учебных целях давайте попробуем решить ее жадным алгоритмом и посчитать математическое ожидания длины получающейся на выходе подпоследовательности.\n",
    "\n",
    "Введем индикаторную случайную величину:\n",
    "\n",
    "\\begin{align}\n",
    "I_{A_i} =\n",
    "\\begin{cases} 1, & \\mbox{ } \\forall j < i \\mbox{ } A_j < A_i \\\\\n",
    "0\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "Тогда:\n",
    "$E\\bigg(\\sum I_{A_i}\\bigg) = \\sum E(I_{A_i}) = \\sum P(A_i) = \\sum \\frac{1}{i} = \\ln(n) + \\gamma + \\epsilon_n$, где $\\epsilon \\rightarrow 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Теорема о математическом ожидании независимых величин**\n",
    "\n",
    "$E(\\xi \\cdot \\psi) = E\\xi \\cdot E\\psi$, если $\\xi$ и $\\psi$ - независимые случайные величины\n",
    "\n",
    "$\\square$\n",
    "\n",
    "$E(\\xi \\cdot \\psi) = \\sum_{z \\in cod(\\xi \\cdot \\psi)} z \\cdot P(\\xi \\cdot \\psi = z) = \\sum_{x \\in cod(\\xi)} \\sum_{y \\in cod(\\psi)} xy \\cdot P(\\xi = x \\cap \\psi = y) = \\sum_{y \\in cod(\\psi)} xy \\cdot P(\\xi = x) \\cdot P(\\psi = y) = E\\xi \\cdot E\\psi$\n",
    "\n",
    "$\\blacksquare$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Дисперсия и ковариация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Определение:** Дисперсия случайной величины $\\xi$ - это $D\\xi = E(\\xi - E\\xi)^2$\n",
    "_Замечание:_ Это второй момент случайной величины. Первый - это $E(|\\xi - E\\xi|)$, n-тый соответственно $E(|\\xi - E\\xi|^n)$\n",
    "\n",
    "+ элементарные св-ва\n",
    "\n",
    "**Определение:** Средне квадратичное отклонение случайно величины $\\xi$ - это $\\sigma = \\sqrt{D\\xi}$\n",
    "\n",
    "**Теорема:** $D\\xi = E\\xi^2 - (E\\xi)^2$\n",
    "\n",
    "$\\square$\n",
    "\n",
    "$D\\xi = \\sum_{\\omega \\in \\Omega} p(\\omega) \\cdot (\\xi(\\omega) - E\\xi) = E\\xi^2 - 2(E\\xi)^2 + (E\\xi)^2 = E\\xi^2 - (E\\xi)^2$\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "**Теорема:** $D(c\\xi) = c^2 \\cdot D\\xi$\n",
    "\n",
    "$\\square$\n",
    "\n",
    "$D(c\\xi) = E(c^2 \\cdot \\xi^2) - (E(c\\xi)^2) = c^2 \\cdot (E\\xi^2 - (E\\xi)^2) = c^2 \\cdot D\\xi$\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "**Теорема:** $D(\\xi + \\psi) = D\\xi + D\\psi$, если $\\xi$ и $\\psi$ - это независимые случайные величины\n",
    "\n",
    "$\\square$\n",
    "\n",
    "$D(\\xi + \\psi) = E(\\xi + \\psi - E(\\xi + \\psi)) = E(\\xi^2 + 2\\xi\\psi + \\psi^2) - (E\\xi + E\\psi)^2 = E\\xi^2 + 2 \\cdot E\\xi \\cdot E\\psi + E\\psi^2 - (E\\xi)^2 - (E\\psi)^2 = D\\xi + D\\psi$\n",
    "\n",
    "$\\blacksquare$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "+ неравенства + чернова\n",
    "\n",
    "+ введение в монте-карло\n",
    "\n",
    "+ предельные теоремы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Неравенства Маркова и Чернова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "**Теорема** Неравенство Маркова\n",
    "\n",
    "Пусть $\\xi \\ge 0$ - случайная величина, тогда\n",
    "\n",
    "$\\forall a > 0 \\quad P(\\xi \\ge a) \\le \\frac{E(\\xi)}{a}$\n",
    "\n",
    "$\\square$\n",
    "\n",
    "Заметим, что $I\\{\\xi \\ge a\\} \\le \\frac{\\xi}{a} \\cdot I\\{\\xi \\ge a\\} \\le \\frac{\\xi}{a}$\n",
    "\n",
    "Возьмем матожидание от этого неравенства:\n",
    "\n",
    "$P(\\xi \\ge a) \\le E(\\frac{\\xi}{a}) = \\frac{E(\\xi)}{a}$\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "Рассмотрим $a = k \\cdot E(\\xi)$, тогда по неравенству Маркова $P(\\xi \\ge k \\cdot E(\\xi)) \\le \\frac{1}{k}$. Т.е. вероятность отклониться от матожидания в $k$ раз меньше чем $\\frac{1}{k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теорема** Неравенство Чебышева\n",
    "\n",
    "Пусть $\\xi$ - случайная величина с конечной дисперсией, тогда\n",
    "\n",
    "$\\forall \\epsilon > 0 \\quad P(|\\xi - E(\\xi)| \\ge \\epsilon) \\le \\frac{D(\\xi)}{\\epsilon^2}$\n",
    "\n",
    "$\\square$\n",
    "\n",
    "$P(|\\xi - E(\\xi)| \\ge \\epsilon) = P((\\xi - E(\\xi))^2 \\le \\epsilon^2) \\le \\frac{E((\\xi - E(\\xi))^2)}{\\epsilon^2} = \\frac{D(\\xi)}{\\epsilon^2}$\n",
    "\n",
    "$\\blacksquare$\n",
    "\n",
    "**Следствие:**\n",
    "\n",
    "Пусть $\\xi$ - случайная величина, $D(\\xi)$ конечна, тогда\n",
    "\n",
    "$\\forall \\epsilon > 0 \\quad P(\\xi \\in [E(\\xi) - \\epsilon \\cdot \\sqrt{D(\\xi)}, E(\\xi) + \\epsilon \\cdot \\sqrt{D(\\xi)}]) \\ge 1 - \\frac{1}{\\epsilon^2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Закон больших чисел"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теорема:** Закон больших чисел\n",
    "\n",
    "Пусть $\\xi_n$ - последовательность независимых одинаково распределенных случайных величин\n",
    "\n",
    "$P(A)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Условные матожидания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пусть $\\xi$ - случайная величина, $B$ - событие : $P(B) > 0$, тогда\n",
    "\n",
    "**Определение:** Условное математическое ожидание $E(\\xi | B) = \\frac{E(\\xi \\cdot I_B)}{P(B)} = \\sum_{\\omega \\in B} \\xi(\\omega) \\cdot \\frac{P(\\{ \\omega \\})}{P(B)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Случайные блуждания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Мартингалы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Цепи маркова"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Другое"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "+ цпт\n",
    "+ стохастическая теорема"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
