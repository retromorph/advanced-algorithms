{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Теория вероятностей"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Базовые понятия"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Определение:** Конечное вероятностное пространство (finite probability space) - это тройка $\\langle\\Omega, \\rho, P\\rangle$, где\n",
    "1. $\\Omega$ - конечное множество элементарных исходов (sample space)\n",
    "2. $\\rho: \\Omega \\longrightarrow [0, 1]$ - функция вероятности элементарного исхода (probability function), такая что $\\sum_{\\omega \\in \\Omega} \\rho(\\omega) = 1$\n",
    "3. $P: 2^\\Omega \\longrightarrow [0, 1]$ - вероятностная мера (probability measure), такая что $P(A) = \\sum_{\\omega \\in \\Omega} \\rho(\\omega)$\n",
    "\n",
    "_Замечание:_ В общем случае $\\Omega$ может быть бесконечным множеством. В таком случае $P$ будет являться произвольной мерой на этом множестве. Например $\\Omega = \\mathbb{R}^2$ с мерой Лебега (т. е. c площадью). Строго мы это не вводим, но пользоваться можно. Это еще называют геометрической вероятностью\n",
    "\n",
    "\n",
    "**Определение:** Событие называется невозможным (impossible event), если $P(A) = 0$\n",
    "**Определение:** Событие называется достоверным (sure event), если $P(A) = 1$\n",
    "\n",
    "**Определение:** Условная вероятность (conditional probability) - вероятность наступления события $A$ при наступившем событии $B$. Вычисляется по формуле $P(A | B) = \\frac{P(A \\cap B)}{P(B)}$\n",
    "\n",
    "**Определение:** События $A$ и $B$ называются независимыми (independent), если $P(A \\cap B) = P(A) \\cdot P(B)$ или, что эквивалентно $P(A | B) = P(A)$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Пусть $\\left\\{ A_1, A_2, ..., A_n \\right\\}$ - мн-во событий, тогда\n",
    "**Определение:** Оно называется попарно независимым, если $\\forall i, j < n$ $A_i$ и $A_j$ - независимы\n",
    "**Определение:** Оно называется независимым в совокупности, если они все одновременно независимы\n",
    "\n",
    "**Пример:**\n",
    "Продемонстрируем разницу между попарной независимостью и независимостью в совокупности.\n",
    "Пусть $\\Omega$ - бросание двух кубиков\n",
    "Выберем такие события:\n",
    "1. На первом кубике выпало четное число\n",
    "2. На втором кубике выпало четное число\n",
    "3. Сумма чисел на двух кубиках четна\n",
    "\n",
    "Это события являются попарно независимыми, но не в совокупности."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Определение:** Множество событий $\\left\\{ A_1, A_2, ..., A_n \\right\\}$ образует полную группу в вероятностном пространстве $\\Omega$, если:\n",
    " 1. $\\forall A_i, A_j$ $P(A_i \\cap A_j) = 0$, т.е. все события несовместимы\n",
    " 2.  $\\sum_{i}{P(A_i)} = 1$, при этом они покрывают все вероятностное пространство $\\Omega$\n",
    "\n",
    "**Пример:**\n",
    "<br/>\n",
    "<img src=\"../static/IMG_09F686348EDB-1.jpeg\" width=\"400\"/>\n",
    "<br/>\n",
    "\n",
    "Таким образом вероятность события $B$ в этом пространстве $\\Omega$ можно выразить через элементы полной группы как:\n",
    "$P(B) = \\sum_{i}{P(B | A_i) \\cdot P(A_i)}$\n",
    "\n",
    "<br/>\n",
    "<img src=\"../static/IMG_252744EDB449-1.jpeg\" width=\"400\"/>\n",
    "<br/>\n",
    "\n",
    "_Замечание:_ Это чем-то напоминает факторизацию в алгебре"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Случайные величины"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Определение:** Случайная величина - это произвольная функция $\\xi: \\Omega \\longrightarrow \\mathbb{R}$\n",
    "\n",
    "**Определение:** Случайные величины $\\xi$ и $\\psi$ называются независимыми, если $\\forall x, y \\in \\mathbb{R} (x \\neq y)$ $A = P(\\xi = x)$ и $B = P(\\psi = y)$ - $A$ и $B$ независимы\n",
    "\n",
    "_Замечание:_ По аналогии, можно ввести понятие попарных независимых и независимых в совокупности случайных величин\n",
    "\n",
    "**Пример:**\n",
    "Предположим мы играем в игру с монеткой с такими правилами:\n",
    "1. Если выпал орел, мы теряем 100 рублей\n",
    "2. Если выпала решка, мы получаем 100 рублей\n",
    "\n",
    "Тогда интуитивно можно ввести случайную величину $\\xi$ таким образом:\n",
    "\\begin{align}\n",
    "$\\xi =$ \\begin{cases} -100, & \\mbox{ } \\omega \\mbox{ - орел}\\\\ 100, & \\mbox{ } \\omega \\mbox{ - решка} \\end{cases}\n",
    "\\end{align}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Определение:** Математическое ожидание случайной величины - взвешенное среднее ее значений, т.е. $E\\xi = \\sum_{\\omega \\in \\Omega}{\\xi(\\omega) \\cdot P(\\omega)}$\n",
    "\n",
    "**Замечание:** То же самое можно записать грубо говоря «по Лебегу» $E\\xi = \\sum_{y \\in cod(\\xi)}{y \\cdot P(\\omega : \\xi(\\omega) = y)}$\n",
    "\n",
    "**Пример:**\n",
    "Посчитаем матожидание случайно величины из предыдущего примера с игрой с монеткой:\n",
    "$E\\xi = -100 \\cdot \\frac{1}{2} + 100 \\cdot \\frac{1}{2} = 0$\n",
    "\n",
    "**Теорема о линейности математического ожидания**\n",
    "$E(\\alpha\\xi + \\beta\\psi) = \\alpha \\cdot E\\xi + \\beta \\cdot E\\psi$\n",
    "$\\square$ $E(\\alpha\\xi + \\beta\\psi) = \\sum_{\\omega \\in \\Omega}{\\bigg(\\alpha\\xi(\\omega) + \\beta\\psi(\\omega)\\bigg)} = E(\\alpha\\xi) + E(\\beta\\psi) = \\alpha \\cdot E\\xi + \\beta \\cdot E\\psi$ $\\blacksquare$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Определение:** Индикаторная случайная величина - это функция вида\n",
    "\\begin{align}\n",
    "$I_A(\\omega) =$\n",
    "\\begin{cases}\n",
    "1, & \\mbox{ } \\omega \\in A \\\\\n",
    "0, & \\mbox{ } \\omega \\notin A\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "**Примеры:**\n",
    "\n",
    "Задача о назначениях:\n",
    "Пусть у нас есть множество $A$ работников, множество $T$ работ и функция стоимости $C : A \\times T \\longrightarrow  \\mathbb{R}$. Обычно функция стоимости задается в виде матрицы $C = c_{ij}$\n",
    "Необходимо найти биекцию $f : A \\longrightarrow T$, такую что сумма $\\sum_{a \\in A} C(a, f(a))$ минимальна.\n",
    "\n",
    "В общем случае эта задача решается венгерским алгоритмом, но в обучающих целях рассмотрим, что будет, если мы попытаемся в качестве ответа брать случайную функцию $f$. Посчитаем математическое ожидание:\n",
    "\n",
    "$E\\xi = E\\bigg(\\sum_{i = 1}^{n}\\sum_{j = 1}^{n} I_{c_{ij}} \\cdot c_{ij}\\bigg) = \\sum_{i = 1}^{n}\\sum_{j = 1}^{n} c_{ij} \\cdot E(I_{c_{ij}}) = \\frac{\\sum_{i = 1}^{n}\\sum_{j = 1}^{n} c_{ij}}{n}$\n",
    "\n",
    "Задача максимального разреза:\n",
    "Пусть у нас есть граф $G$.\n",
    "Необходимо найти максимальный разрез этого графа, т.е. такое подмножество вершин, что у максимального количества ребер одна вершина лежит в этом подмножестве, а вторая нет. Например:\n",
    "<br/>\n",
    "<img src=\"../static/IMG_F4D34D90BF7D-1.jpeg\" width=\"1000\">\n",
    "\n",
    "Для этой задачи неизвестен полиномиальный алгоритм решения, поэтому давайте попробуем посчитать матожидание случайного равновероятного выбора вершин в подмножество. Т. е. мы будем проходиться по всем вершинам графа и с вероятностью $\\frac{1}{2}$ брать их в разрез.\n",
    "\n",
    "Введем индикаторную случайную величину:\n",
    "\\begin{align}\n",
    "$I_c = I_{uv} = $\n",
    "\\begin{cases}\n",
    "1, & \\mbox{ } u \\in A, v \\in \\overline{A} \\\\\n",
    "1, & \\mbox{ } u \\in \\overline{A}, v \\in A \\\\\n",
    "0, & \\mbox{ } u \\in A, v \\in A \\\\\n",
    "0, & \\mbox{ } u \\in \\overline{A}, v \\in \\overline{A} \\\\\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "Тогда:\n",
    "$E\\bigg(\\sum I_c\\bigg) = \\sum E(I_c) = \\sum P(A_uv) = \\frac{\\epsilon(G)}{2}$\n",
    "\n",
    "Наибольшая возрастающая подпоследовательность:\n",
    "Пусть у нас есть массив $A$.\n",
    "Необходимо найти наибольший возрастающий подмассив в $A$.\n",
    "\n",
    "Эта задача решается методом динамического программирования, однако в учебных целях давайте попробуем решить ее жадным алгоритмом и посчитать математическое ожидания длины получающейся на выходе подпоследовательности.\n",
    "\n",
    "Введем индикаторную случайную величину:\n",
    "\n",
    "\\begin{align}\n",
    "$I_{A_i} =$\n",
    "\\begin{cases} 1, & \\mbox{ } \\forall j < i \\mbox{ } A_j < A_i \\\\\n",
    "0\n",
    "\\end{cases}\n",
    "\\end{align}\n",
    "\n",
    "Тогда:\n",
    "$E\\bigg(\\sum I_{A_i}\\bigg) = \\sum E(I_{A_i}) = \\sum P(A_i) = \\sum \\frac{1}{i} = \\ln(n) + \\gamma + \\epsilon_n$, где $\\epsilon \\rightarrow 0$\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Теорема**\n",
    "$E(\\xi \\cdot \\psi) = E\\xi \\cdot E\\psi$, если $\\xi$ и $\\psi$ - независимые случайные величины\n",
    "$\\square$\n",
    "$E(\\xi \\cdot \\psi) = \\sum_{z \\in cod(\\xi \\cdot \\psi)} z \\cdot P(\\xi \\cdot \\psi = z) = \\sum_{x \\in cod(\\xi)} \\sum_{y \\in cod(\\psi)} xy \\cdot P(\\xi = x \\cap \\psi = y) = \\sum_{y \\in cod(\\psi)} xy \\cdot P(\\xi = x) \\cdot P(\\psi = y) = E\\xi \\cdot E\\psi$\n",
    "$\\blacksquare$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Дисперсия"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Определение:** Дисперсия случайной величины $\\xi$ - это $D\\xi = E(\\xi - E\\xi)^2$\n",
    "_Замечание:_ Это второй момент случайной величины. Первый - это $E(|\\xi - E\\xi|)$, n-тый соответственно $E(|\\xi - E\\xi|^n)$\n",
    "\n",
    "**Определение:** Средне квадратичное отклонение случайно величины \\xi $\\sigma = \\sqrt{D\\xi}$"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
